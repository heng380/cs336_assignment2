# Model hyperparameters
vocab_size: 10000
context_length: 256
d_model: 512
num_layers: 4
num_heads: 16
d_ff: 1344
rope_theta: 10000.0

# Benchmarking parameters
batch_size: 64
warmup_steps: 5
benchmark_steps: 10
forward_only: false
device: "cuda" 
autocast: false